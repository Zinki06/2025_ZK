# 음성 인식 기반 베이스 생성 및 제스처 제어 시스템

> 음성으로 감정을 분석하고 해당 감정에 맞는 MIDI 베이스라인을 생성한 후, 손 제스처로 실시간 제어하는 인터랙티브 음악 시스템 연구

## 연구 배경과 목적

### 연구 질문
음성에서 추출한 감정 정보를 활용하여 자동으로 베이스 라인을 생성하고, 손 제스처를 통해 실시간으로 제어할 수 있는 직관적인 음악 창작 인터페이스를 구현할 수 있는가?

### 연구 목표
- 음성-텍스트 변환 후 감정 분석을 통한 자동 베이스 라인 생성 알고리즘 구현
- MediaPipe를 활용한 손 제스처 인식 및 MIDI 파라미터 매핑 시스템 개발
- 실시간 상호작용이 가능한 음악 생성 파이프라인 구축

### 예상 난이도
고급 - 다중 모달 AI 시스템 통합, 실시간 처리, MIDI 프로토콜 활용

## 최종 성과 요약

### 핵심 성능 지표
- **음성 인식 정확도**: Whisper API 기반 95% 이상
- **감정 분석 정확도**: GPT-4o 기반 5단계 분류 90% 이상
- **제스처 인식 응답 속도**: MediaPipe 기반 30fps 실시간 처리
- **MIDI 생성 지연시간**: 평균 200ms 이내

### 구현된 주요 기능
1. **음성 처리 파이프라인**: 실시간 VAD → STT → 감정 분석
2. **MIDI 생성 시스템**: 감정별 프리셋 기반 베이스 라인 자동 생성
3. **제스처 제어 인터페이스**: 양손 랜드마크 추출 및 파라미터 매핑
4. **통합 GUI**: 원클릭 녹음 및 실시간 피드백 시스템

## 시스템별 상세 분석

### 1. 음성 감정 분석 시스템

#### 이론적 배경
OpenAI Whisper-1 모델을 통한 음성-텍스트 변환 후, GPT-4o를 활용한 텍스트 기반 감정 분석을 수행함. 감정은 5단계 스케일(슬픔-평온-중립-행복-흥분)로 분류됨.

#### 구현 알고리즘
```
음성 입력 → VAD 감지 → WAV 변환 → Whisper STT → GPT-4o 감정 분석 → 감정 번호(1-5)
```

#### 성능 측정
- **STT 정확도**: 영어 95.2%, 한국어 92.8%
- **감정 분석 일관성**: 동일 텍스트 반복 테스트 시 95% 일치
- **처리 속도**: 평균 3초 음성 → 1.2초 처리

상세 성능 분석 결과는 [results/performance_results.txt](results/performance_results.txt)에서 확인 가능함.

### 2. MIDI 생성 및 제어 시스템

#### 이론적 배경
감정별 사전 정의된 프리셋(조성, 템포, 리듬 패턴)을 바탕으로 MIDI 메시지를 생성함. 각 감정에 대응하는 음악적 특성을 정량화하여 매핑함.

#### 감정-음악 매핑 테이블

| 감정 | 조성 | 템포(BPM) | 리듬 패턴 | 특징 |
|------|------|-----------|-----------|------|
| 슬픔(1) | A Minor | 70 | long sustain | 낮은 음역, 긴 지속음 |
| 평온(2) | G Major | 90 | smooth quarter | 안정적 진행 |
| 중립(3) | C Major | 100 | steady eighth | 균형잡힌 패턴 |
| 행복(4) | D Major | 120 | syncopated eighth | 경쾌한 싱코페이션 |
| 흥분(5) | E Minor | 140 | driving sixteenth | 빠른 16분음표 |

#### MIDI 메시지 생성 성능
- **메시지 생성 속도**: 4음표 베이스라인 기준 평균 50ms
- **타이밍 정확도**: ±5ms 이내 오차

감정별 프리셋 검증 결과는 [results/emotion_mapping_results.txt](results/emotion_mapping_results.txt)에서 확인 가능함.

### 3. 손 제스처 인식 시스템

#### 이론적 배경
MediaPipe Hands 솔루션을 활용하여 21개 손 랜드마크를 실시간 추출함. 주요 제스처 파라미터는 엄지-검지 거리, 손목 위치, 양손 간 거리로 설정함.

#### 제스처-파라미터 매핑
- **왼손**: 리듬 복잡도, 옥타브, 패턴 변경
  - 엄지-검지 거리: 0.0~0.3 → 복잡도 조절
  - Y 위치: 상단(0.0) → 고음역, 하단(1.0) → 저음역
- **오른손**: 필터 컷오프, 피치 벤드, 이펙트 조절
  - 엄지-검지 거리: 0.0~0.3 → 필터 조절
  - X 위치: 좌측(0.0) → 낮은 값, 우측(1.0) → 높은 값
- **양손 거리**: 0.0~1.0 → 마스터 템포 조절

#### 인식 성능 분석
- **프레임 처리 속도**: 평균 33fps (30fps 목표 달성)
- **랜드마크 정확도**: 적절한 조명 환경에서 98% 인식률
- **스무딩 효과**: 0.8 계수 적용으로 떨림 현상 90% 감소

### 4. 시스템 통합 및 최적화

#### 멀티스레딩 구조
- **메인 스레드**: GUI 및 사용자 인터랙션
- **오디오 스레드**: 실시간 음성 캡처 및 처리
- **비디오 스레드**: 웹캠 영상 처리 및 제스처 인식
- **MIDI 스레드**: 실시간 MIDI 메시지 전송

#### 성능 최적화 결과
- **메모리 사용량**: 평균 150MB (초기 300MB에서 50% 개선)
- **CPU 사용률**: 평균 25% (Intel i5 기준)
- **전체 지연시간**: 음성 입력부터 MIDI 출력까지 평균 1.8초

## 기술적 한계와 개선 방향

### 현재 한계점
1. **네트워크 의존성**: OpenAI API 호출로 인한 인터넷 연결 필수
2. **언어 제약**: 한국어 감정 분석 정확도가 영어 대비 낮음
3. **조명 민감성**: 제스처 인식이 조명 환경에 영향을 받음
4. **단일 사용자**: 현재 구조는 한 명의 사용자만 지원

### 향후 개선 방향
1. **오프라인 모델**: 로컬 감정 분석 모델 도입으로 응답 속도 개선
2. **다국어 지원**: 한국어 특화 감정 분석 모델 훈련
3. **고급 제스처**: Leap Motion 센서 연동으로 정밀도 향상
4. **협업 기능**: 다중 사용자 동시 제스처 인식 시스템

## 실험 환경과 재현성

### 소프트웨어 환경
- **운영체제**: macOS 14.6+ / Windows 10+ / Linux Ubuntu 20.04+
- **Python 버전**: 3.11.11
- **주요 의존성**: 
  - OpenAI API 1.16.0
  - MediaPipe 0.10.21
  - OpenCV 4.8.1
  - MIDO 1.3.2

### 하드웨어 요구사항
- **프로세서**: Intel i5 이상 또는 동급 AMD
- **메모리**: 8GB RAM 이상
- **웹캠**: 720p 이상 해상도 지원
- **MIDI**: 가상 MIDI 포트 지원 (macOS: IAC Driver, Windows: loopMIDI)

### 실행 방법
```bash
# 저장소 복제 및 환경 설정
git clone https://github.com/Zinki06/Vibe-HandTune_withLLM.git
cd Vibe-HandTune_withLLM
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# OpenAI API 키 설정
echo "OPENAI_API_KEY='your-api-key'" > .env

# 전체 시스템 실행
python main.py

# 개별 모듈 테스트
python main.py --mode stt      # 음성 인식 테스트
python main.py --mode emotion  # 감정 분석 테스트
python main.py --mode gesture  # 제스처 인식 테스트
python main.py --mode midi     # MIDI 출력 테스트
```

## 사용 기술

### AI 및 음성 처리
- **OpenAI Whisper**: 실시간 음성-텍스트 변환
- **GPT-4o**: 텍스트 기반 감정 분석
- **SoundDevice**: 실시간 오디오 입출력

### 컴퓨터 비전
- **MediaPipe**: 손 랜드마크 추출 및 추적
- **OpenCV**: 웹캠 영상 처리

### 음악 및 MIDI
- **MIDO**: MIDI 메시지 생성 및 전송
- **python-rtmidi**: 실시간 MIDI 통신

### 사용자 인터페이스
- **CustomTkinter**: 현대적 GUI 인터페이스
- **NumPy**: 오디오 데이터 처리

각 모듈의 상세 구현과 테스트 결과는 개별 소스 파일에서 확인 가능함.